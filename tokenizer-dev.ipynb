{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ee086c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ï¼µï½ï½‰ï½ƒï½ï½„ï½…! ğŸ…¤ğŸ…ğŸ…˜ğŸ…’ğŸ…ğŸ…“ğŸ…”â€½ ğŸ‡ºâ€ŒğŸ‡³â€ŒğŸ‡®â€ŒğŸ‡¨â€ŒğŸ‡´â€ŒğŸ‡©â€ŒğŸ‡ª! ğŸ˜„ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to â€œsupport Unicodeâ€ in our software (whatever that meansâ€”like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I donâ€™t blame programmers for still finding the whole thing mysterious, even 30 years after Unicodeâ€™s inception.\"\n",
    "tokens = text.encode(\"utf-8\")\n",
    "tokens = list(map(int, tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "3ce5304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair_count(data):\n",
    "    count = {}\n",
    "    for pair in zip(data, data[1:]):\n",
    "        count[pair] = count.get(pair, 0) + 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0b552052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(ids, pair, idx):\n",
    "    \"\"\"Replaces the `pair` with the `idx` whenever it appears in the `ids`\"\"\"\n",
    "    newids = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) - 1 and (ids[i], ids[i + 1]) == pair:\n",
    "            newids.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newids.append(ids[i])\n",
    "            i += 1\n",
    "    return newids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "a7ea558e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging pair (101, 32) into a new token 256\n",
      "merging pair (240, 159) into a new token 257\n",
      "merging pair (226, 128) into a new token 258\n",
      "merging pair (105, 110) into a new token 259\n",
      "merging pair (115, 32) into a new token 260\n",
      "merging pair (97, 110) into a new token 261\n",
      "merging pair (116, 104) into a new token 262\n",
      "merging pair (257, 133) into a new token 263\n",
      "merging pair (257, 135) into a new token 264\n",
      "merging pair (97, 114) into a new token 265\n",
      "merging pair (239, 189) into a new token 266\n",
      "merging pair (258, 140) into a new token 267\n",
      "merging pair (267, 264) into a new token 268\n",
      "merging pair (101, 114) into a new token 269\n",
      "merging pair (111, 114) into a new token 270\n",
      "merging pair (116, 32) into a new token 271\n",
      "merging pair (259, 103) into a new token 272\n",
      "merging pair (115, 116) into a new token 273\n",
      "merging pair (261, 100) into a new token 274\n",
      "merging pair (32, 262) into a new token 275\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 276\n",
    "num_merges = vocab_size - 256\n",
    "ids = list(tokens)\n",
    "\n",
    "merges = {}\n",
    "for i in range(num_merges):\n",
    "    stats = pair_count(ids)\n",
    "    pair = max(stats, key=stats.get)\n",
    "    idx = 256 + i\n",
    "    ids = merge(ids, pair, idx)\n",
    "    print(f\"merging pair {pair} into a new token {idx}\")\n",
    "    merges[pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1274b518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616\n",
      "451\n",
      "1.37x compression\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(ids))\n",
    "print(f\"{len(tokens) / len(ids):.2f}x compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "3db29486",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "for (p0, p1), idx in merges.items():\n",
    "    vocab[idx] = vocab[p0] + vocab[p1]\n",
    "\n",
    "\n",
    "def decode(ids):\n",
    "    tokens = b\"\".join(vocab[idx] for idx in ids)\n",
    "    text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "880a6f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    tokens = list(text.encode(\"utf-8\"))\n",
    "    while len(tokens) >= 2:\n",
    "        stats = pair_count(tokens)\n",
    "        pair = min(stats, key=lambda p: merges.get(p, float(\"inf\")))\n",
    "        if pair not in merges:\n",
    "            break\n",
    "        idx = merges[pair]\n",
    "        tokens = merge(tokens, pair, idx)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881ed14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï¼µï½ï½‰ï½ƒï½ï½„ï½…! ğŸ…¤ğŸ…ğŸ…˜ğŸ…’ğŸ…ğŸ…“ğŸ…”â€½ ğŸ‡ºâ€ŒğŸ‡³â€ŒğŸ‡®â€ŒğŸ‡¨â€ŒğŸ‡´â€ŒğŸ‡©â€ŒğŸ‡ª! ğŸ˜„ The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to â€œsupport Unicodeâ€ in our software (whatever that meansâ€”like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I donâ€™t blame programmers for still finding the whole thing mysterious, even 30 years after Unicodeâ€™s inception.\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a16662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', \"'ve\", ' world', '123', ' how', \"'s\", ' are', ' you', '!!!?']\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "gpt2pat = re.compile(\n",
    "    r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    ")\n",
    "\n",
    "print(re.findall(gpt2pat, \"Hello've world123 how's are you!!!?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c1f9cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1336, 1900, 1695, 449, 499]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "enc.encode(\"whats good with you\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
